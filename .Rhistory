#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(con_fn %in% duplicate_t2_fn & con_ln %!in% duplicate_t2_ln)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(con_fn %in% duplicate_t2_fn & !con_ln %in% duplicate_t2_ln)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(!con_fn %in% duplicate_t2_fn & con_ln %in% duplicate_t2_ln)
nd_t2_ln<-duplicates(!t2_raw$con_ln)
nd_t2_ln<-!duplicates(t2_raw$con_ln)
nd_t2_ln<-negate(duplicates(t2_raw$con_ln))
nd_t2_ln<-Negate(duplicates(t2_raw$con_ln))
nd_t2_ln<-t2_raw %>%
Negate(duplicates(con_ln))
nd_t2_ln<-t2_raw %>%
Negate(duplicates(con_ln))
nd_t2_ln<- -duplicates(t2_raw$con_ln)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(con_fn %in% duplicate_t2_fn & con_fn %in% t2_raw) %>%
dplyr::distinct(!con_fn)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(con_fn %in% duplicate_t2_fn & con_fn %in% t2_raw) %>%
dplyr::distinct(!con_fn %in% duplicate_t2_fn)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(con_fn %in% duplicate_t2_fn & con_fn %in% t2_raw) %>%
dplyr::distinct(con_fn %in% duplicate_t2_fn)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(con_fn %in% duplicate_t2_fn & con_fn %in% t2_raw) %>%
dplyr::distinct(duplicate_t2_fn)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(con_fn %in% duplicate_t2_fn & con_fn %in% t2_raw) %>%
dplyr::distinct(con_fn)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(con_fn %in% duplicate_t2_fn & con_fn %in% t2_raw) %>%
dplyr::unique(con_fn)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(con_fn %in% duplicate_t2_fn & con_fn %in% t2_raw) %>%
unique(con_fn)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(con_fn %in% duplicate_t2_fn & con_fn %in% t2_raw) %>%
unique(t2_raw$con_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(con_fn %in% duplicate_t2_fn & con_fn %in% t2_raw) %>%
!duplicated(con_fn)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
t2_raw<-t2_raw %>%
dplyr::filter(con_ln %in% duplicate_t2_ln & con_fn %in% duplicate_t2_fn) %>%
dplyr::filter(con_fn %in% duplicate_t2_fn & con_fn %in% t2_raw) %>%
!duplicated(t2_raw$con_fn)
install.packages("klaR")
install.packages("heplots")
install.packages("klaR")
install.packages(c("heplots", "rattle"))
install.packages("rattle")
install.packages("heplots")
install.packages("klaR")
#Discriminant Analysis example--------------------------------------
library(rattle) #has the wine dataset
library(heplots) #for Box's M test
library(MASS) #for quadratic discriminant analysis
library(klaR) #for partition plots
#load the data
data(wine)
attach(wine)
#check assumption for lda
?boxM
attach(wine)
#check assumption for lda
?boxM
View(wine)
#random partition into train and test sets
## 75% of the sample size
smp_size = floor(0.75 * nrow(wine))
## set the seed to make your partition reproducible
set.seed(1337)
train_ind = sample(seq_len(nrow(wine)), size = smp_size)
train = wine[train_ind, ]
test = wine[-train_ind, ]
wine.qda = qda(Type ~ ., data = train)
predicted.qda = predict(wine.qda, newdata = test)
#table
table(test$Type, predicted.qda$class, dnn = c('Actual Group','Predicted Group'))
?boxM
boxM(wine[,2:14],Type)
#check assumption for lda
?boxM
#check assumption for lda
??boxM
# Model accuracy
mean(predicted.qda$class == test$Type)
partimat(wine[,2:5],Type,data=test,method="qda",main="Partition Plots")
#Logistic regression example--------------------------------------
#let's predict whether a car has manual or automatic transmission
?mtcars
#random partition into train and test sets
## 75% of the sample size
smp_size = floor(0.75 * nrow(mtcars))
## set the seed to make your partition reproducible
set.seed(1337)
train_ind = sample(seq_len(nrow(mtcars)), size = smp_size)
train = mtcars[train_ind, ]
test = mtcars[-train_ind, ]
car.logit = glm(am ~ ., data = train, family="binomial")
predicted.logit = predict(car.logit, newdata = test, type="response")
#fit logistic regression model to mtcars data
car.logit = glm(am ~ ., data = train, family="binomial")
predicted.logit = predict(car.logit, newdata = test, type="response")
predicted.logit = predict(car.logit, newdata = test, type="response")
#probability cutoff alpha = .5
predicted.logit
classification = ifelse(predicted.logit > .5, 1, 0)
classification
#table
table(test$am, classification, dnn = c('Actual Group','Predicted Group'))
# Model accuracy
mean(classification == test$am)
qf(.95, df1= 1.46834, df2 = 10.27838)
qf(.95, df1= \1.46834, df2 = \10.27838)
qf(.95, df1= 1.46834, df2 = 10.27838)
wisc_data<-read.csv(file.choose())
names(wisc_data) = c("Thickness","Uniformity_size","Uniformity_shape",
"Adhesion","Cell_size","Bare_nuclei","Bland_chromatin",
"Normal_nuclei","Mitoses","cancer")
attach(wisc_data)
wisc_data$Bare_nuclei= as.integer(Bare_nuclei)
wisc_data$Bare_nuclei= as.integer(Bare_nuclei)
wisc_data$cancer = as.factor(cancer)
install.packages("heplots")
library(heplots)
?wisc_data
attach(wisc_data)
wisc_data$Bare_nuclei= as.integer(Bare_nuclei)
wisc_data$cancer = as.factor(cancer)
?boxM
View(wisc_data)
View(wisc_data)
boxM(wisc_data[ ,1:9], cancer)
smp_size = floor(0.80 * nrow(wisc_data))
smp_size = floor(0.75 * nrow(wine))
smp_size = floor(0.75 * nrow(wisc_data))
set.seed(1337)
train_ind = sample(seq_len(nrow(wisc_data), size = smp_size)
train = wine[train_ind, ]
test = wine[-train_ind, ]
train_ind = sample(seq_len(nrow(wisc_data)), size = smp_size)
train = wine[train_ind, ]
test = wine[-train_ind, ]
train = wisc_data[train_ind, ]
test = wisc_data[-train_ind, ]
wisc.qda = qda(Type ~ ., data = train)
wisc_data.qda = qda(Type ~ ., data = train)
wisc_data.qda = qda(cancer ~ ., data = train)
predicted.qda = predict(wisc_data.qda, newdata = test)
table(test$Type, predicted.qda$class, dnn = c('Actual Group','Predicted Group'))
smp_size = floor(0.75 * nrow(wisc_data))
set.seed(1337)
train_ind = sample(seq_len(nrow(wisc_data)), size = smp_size)
train = wisc_data[train_ind, ]
test = wisc_data[-train_ind, ]
wisc_data.qda = qda(cancer ~ ., data = train)
predicted.qda = predict(wisc_data.qda, newdata = test)
table(test$Type, predicted.qda$class, dnn = c('Actual Group','Predicted Group'))
table(test$cancer, predicted.qda$class, dnn = c('Actual Group','Predicted Group'))
mean(predicted.qda$class == test$cancer)
smp_size = floor(0.75 * nrow(wisc_data))
set.seed(1337)
train_ind = sample(seq_len(nrow(wisc_data)), size = smp_size)
train = wisc_data[train_ind, ]
test = wisc_data[-train_ind, ]
wisc_data.logit = glm(am ~ ., data = train, family="binomial")
wisc_data.logit = glm(cancer ~ ., data = train, family="binomial")
predicted.logit = predict(wisc_data.logit, newdata = test, type="response")
predicted.logit
classification = ifelse(predicted.logit > .5, 1, 0)
classification
table(test$cancer, classification, dnn = c('Actual Group','Predicted Group'))
mean(classification == test$cancer)
freezing_raw<-read.csv(file.choose())
## Remove unneeded columns from the dataset, refer to data dictionary for more info
freezing_raw<-dplyr::select(freezing_raw,-c(redcap_survey_identifier,consent_form_timestamp,
sona_id,con_date,con_sig,con_email,consent_form_complete,
asi_timestamp,asi_complete,pswq_timestamp,pswq_complete,
rrq_timestamp,rrq_complete,sias_timestamp,sias_complete,
masq_timestamp,masq_complete,lec_timestamp,lec_complete,
siasii_timestamp,siasii_complete,afq_timestamp,afq_complete,
afqs_timestamp,afqs_complete,panas_timestamp,panas_complete,
atq_timestamp,atq_complete,brief_timestamp,brief_complete,
debriefing_form_timestamp,debriefing_form_complete))
## Convert first and last name columns to characters
freezing_raw$con_fn <- as.character(freezing_raw$con_fn)
freezing_raw$con_ln <- as.character(freezing_raw$con_ln)
### Make sure conversion worked - diagnostic steps ###
## examine the class of first and last name columns
typeof(freezing_raw$con_fn)
typeof(freezing_raw$con_ln)
## examine the structure of first and last name columns
str(freezing_raw$con_fn)
str(freezing_raw$con_ln)
## specifying column index 390 = exclusion of any incomplete data ##
freezing_raw<-freezing_raw[complete.cases(freezing_raw[ , 390]),]
### extract repeat participants ###
duplicates(freezing_raw$con_fn)
duplicates(freezing_raw$con_ln)
duplicate_fn<-duplicates(freezing_raw$con_fn)
duplicate_ln<-duplicates(freezing_raw$con_ln)
str(duplicate_fn)
duplicate_names<-append(duplicate_fn, duplicate_ln)
duplicates(duplicate_names)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(con_ln %in% duplicate_ln & con_fn %in% duplicate_fn)
View(t2_raw)
?tidyr::unite
freezing_raw$name<-tidyr::unite(freezing_raw, con_fn, con_ln, sep = " ", remove = TRUE)
View(freezing_raw)
View(freezing_raw)
View(freezing_raw)
View(freezing_raw)
View(freezing_raw)
tidyr::unite(freezing_raw, name, con_fn:con_ln, sep = " ", remove = TRUE)
View(freezing_raw)
freezing_raw<-read.csv(file.choose())
## Remove unneeded columns from the dataset, refer to data dictionary for more info
freezing_raw<-dplyr::select(freezing_raw,-c(redcap_survey_identifier,consent_form_timestamp,
sona_id,con_date,con_sig,con_email,consent_form_complete,
asi_timestamp,asi_complete,pswq_timestamp,pswq_complete,
rrq_timestamp,rrq_complete,sias_timestamp,sias_complete,
masq_timestamp,masq_complete,lec_timestamp,lec_complete,
siasii_timestamp,siasii_complete,afq_timestamp,afq_complete,
afqs_timestamp,afqs_complete,panas_timestamp,panas_complete,
atq_timestamp,atq_complete,brief_timestamp,brief_complete,
debriefing_form_timestamp,debriefing_form_complete))
## Convert first and last name columns to characters
freezing_raw$con_fn <- as.character(freezing_raw$con_fn)
freezing_raw$con_ln <- as.character(freezing_raw$con_ln)
### Make sure conversion worked - diagnostic steps ###
## examine the class of first and last name columns
typeof(freezing_raw$con_fn)
typeof(freezing_raw$con_ln)
## specifying column index 390 = exclusion of any incomplete data ##
freezing_raw<-freezing_raw[complete.cases(freezing_raw[ , 390]),]
tidyr::unite(freezing_raw, name, con_fn:con_ln, sep = " ", remove = TRUE)
View(freezing_raw)
tidyr::unite(freezing_raw, name, con_fn:con_ln, sep = " ", remove = TRUE)
freezing_raw<-tidyr::unite(freezing_raw, name, con_fn:con_ln, sep = " ", remove = TRUE)
str(freezing_raw$name)
duplicate_names<-duplicates(freezing_raw$name)
duplicates(duplicate_names)
duplicate_names
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(names %in% duplicate_names)
#Generate a new data set for Time 2
t2_raw<-freezing_raw %>%
dplyr::filter(name %in% duplicate_names)
View(t2_raw)
View(t2_raw)
names_total<-as.vector(freezing_raw$name)
duplicates(names_total)
?return
?grepl
?grepl
grepl(duplicate_names, names_total)
grep(duplicate_names, names_total)
### extract repeat participants ###
dup_name_data<-duplicates(freezing_raw$name)
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(duplicates(freezing_raw$name))
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(duplicates(freezing_raw$name))
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(duplicates(name))
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(duplicates(freezing_raw %in% duplicate_names))
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(!duplicated(name))
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(duplicated(name))
View(dup_name_data)
trimws(freezing_raw$name)
freezing_raw<-read.csv(file.choose())
## Remove unneeded columns from the dataset, refer to data dictionary for more info
freezing_raw<-dplyr::select(freezing_raw,-c(redcap_survey_identifier,consent_form_timestamp,
sona_id,con_date,con_sig,con_email,consent_form_complete,
asi_timestamp,asi_complete,pswq_timestamp,pswq_complete,
rrq_timestamp,rrq_complete,sias_timestamp,sias_complete,
masq_timestamp,masq_complete,lec_timestamp,lec_complete,
siasii_timestamp,siasii_complete,afq_timestamp,afq_complete,
afqs_timestamp,afqs_complete,panas_timestamp,panas_complete,
atq_timestamp,atq_complete,brief_timestamp,brief_complete,
debriefing_form_timestamp,debriefing_form_complete))
## Convert first and last name columns to characters
freezing_raw$con_fn <- as.character(freezing_raw$con_fn)
freezing_raw$con_ln <- as.character(freezing_raw$con_ln)
### Make sure conversion worked - diagnostic steps ###
## examine the class of first and last name columns
typeof(freezing_raw$con_fn)
typeof(freezing_raw$con_ln)
## specifying column index 390 = exclusion of any incomplete data ##
freezing_raw<-freezing_raw[complete.cases(freezing_raw[ , 390]),]
trimws(freezing_raw$name)
trimws(freezing_raw$con_fn)
trimws(freezing_raw$con_ln)
freezing_raw$con_fn<-trimws(freezing_raw$con_fn)
freezing_raw$con_ln<-trimws(freezing_raw$con_ln)
## Uniting first name and last name into one column ##
freezing_raw<-tidyr::unite(freezing_raw, name, con_fn:con_ln, sep = " ", remove = TRUE)
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(duplicated(name))
View(dup_name_data)
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(duplicates(name))
?duplicated
?duplicates
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(duplicates(name %in% duplicate_names))
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(duplicates(duplicate_names %in% name))
View(freezing_raw)
View(dup_name_data)
freezing_raw<-read.csv(file.choose())
## Remove unneeded columns from the dataset, refer to data dictionary for more info
freezing_raw<-dplyr::select(freezing_raw,-c(redcap_survey_identifier,consent_form_timestamp,
sona_id,con_date,con_sig,con_email,consent_form_complete,
asi_timestamp,asi_complete,pswq_timestamp,pswq_complete,
rrq_timestamp,rrq_complete,sias_timestamp,sias_complete,
masq_timestamp,masq_complete,lec_timestamp,lec_complete,
siasii_timestamp,siasii_complete,afq_timestamp,afq_complete,
afqs_timestamp,afqs_complete,panas_timestamp,panas_complete,
atq_timestamp,atq_complete,brief_timestamp,brief_complete,
debriefing_form_timestamp,debriefing_form_complete))
## Convert first and last name columns to characters
freezing_raw$con_fn <- as.character(freezing_raw$con_fn)
freezing_raw$con_ln <- as.character(freezing_raw$con_ln)
### Make sure conversion worked - diagnostic steps ###
## examine the class of first and last name columns
typeof(freezing_raw$con_fn)
typeof(freezing_raw$con_ln)
## specifying column index 390 = exclusion of any incomplete data ##
freezing_raw<-freezing_raw[complete.cases(freezing_raw[ , 390]),]
freezing_raw$con_fn<-trimws(freezing_raw$con_fn)
freezing_raw$con_ln<-trimws(freezing_raw$con_ln)
## Uniting first name and last name into one column ##
freezing_raw<-tidyr::unite(freezing_raw, name, con_fn:con_ln, sep = " ", remove = TRUE)
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(duplicates(duplicate_names %in% name))
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(duplicated(name))
View(dup_name_data)
freezing_raw<-read.csv(file.choose())
## Remove unneeded columns from the dataset, refer to data dictionary for more info
freezing_raw<-dplyr::select(freezing_raw,-c(redcap_survey_identifier,consent_form_timestamp,
sona_id,con_sig,con_email,consent_form_complete,
asi_timestamp,asi_complete,pswq_timestamp,pswq_complete,
rrq_timestamp,rrq_complete,sias_timestamp,sias_complete,
masq_timestamp,masq_complete,lec_timestamp,lec_complete,
siasii_timestamp,siasii_complete,afq_timestamp,afq_complete,
afqs_timestamp,afqs_complete,panas_timestamp,panas_complete,
atq_timestamp,atq_complete,brief_timestamp,brief_complete,
debriefing_form_timestamp,debriefing_form_complete))
## Convert first and last name columns to characters
freezing_raw$con_fn <- as.character(freezing_raw$con_fn)
freezing_raw$con_ln <- as.character(freezing_raw$con_ln)
### Make sure conversion worked - diagnostic steps ###
## examine the class of first and last name columns
typeof(freezing_raw$con_fn)
## specifying column index 390 = exclusion of any incomplete data ##
freezing_raw<-freezing_raw[complete.cases(freezing_raw[ , 390]),]
freezing_raw$con_fn<-trimws(freezing_raw$con_fn)
freezing_raw$con_ln<-trimws(freezing_raw$con_ln)
## Uniting first name and last name into one column ##
freezing_raw<-tidyr::unite(freezing_raw, name, con_fn:con_ln, sep = " ", remove = TRUE)
### extract repeat participants ###
dup_name_data<-freezing_raw %>%
dplyr::filter(duplicated(name))
View(dup_name_data)
### extract repeat participants & Generate a new data set for Time 2 ###
T2_data<-freezing_raw %>%
dplyr::filter(duplicated(name))
View(T2_data)
freezing_raw<-freezing_raw %>%
dplyr::distinct(name)
View(freezing_raw)
?distinct
##Import data##
freezing_raw<-read.csv(file.choose())
## Remove unneeded columns from the dataset, refer to data dictionary for more info
freezing_raw<-dplyr::select(freezing_raw,-c(redcap_survey_identifier,consent_form_timestamp,
sona_id,con_sig,con_email,consent_form_complete,
asi_timestamp,asi_complete,pswq_timestamp,pswq_complete,
rrq_timestamp,rrq_complete,sias_timestamp,sias_complete,
masq_timestamp,masq_complete,lec_timestamp,lec_complete,
siasii_timestamp,siasii_complete,afq_timestamp,afq_complete,
afqs_timestamp,afqs_complete,panas_timestamp,panas_complete,
atq_timestamp,atq_complete,brief_timestamp,brief_complete,
debriefing_form_timestamp,debriefing_form_complete))
## clear white space in first and last name columns
freezing_raw$con_fn<-trimws(freezing_raw$con_fn)
freezing_raw$con_ln<-trimws(freezing_raw$con_ln)
## Uniting first name and last name into one column ##
freezing_raw<-tidyr::unite(freezing_raw, name, con_fn:con_ln, sep = " ", remove = TRUE)
## Convert name column to character
freezing_raw$name <- as.character(freezing_raw$name)
## specifying column index 390 = exclusion of any incomplete data ##
freezing_raw<-freezing_raw[complete.cases(freezing_raw[ , 390]),]
### extract repeat participants & Generate a new data set for Time 2 ###
T2_data<-freezing_raw %>%
dplyr::filter(duplicated(name))
freezing_raw_d<-freezing_raw %>%
dplyr::distinct(name, .keep_all = TRUE)
View(freezing_raw_d)
View(dup_name_data)
####libraries
library(psych)
####libraries
library(psych)
library(GPArotation)
library(nFactors)
####Exploratory Factor Analysis####
install.packages(nFactors)
####Exploratory Factor Analysis####
install.packages("nFactors")
library(nFactors)
####load data
data(bfi)
head(bfi)
head(bfi)
str(bfi)
describe(bfi)
View(bfi)
pairs.panels(bfi)
efa.3.ort<-fa(bfi[,1:25], nfactors = 3, rotate = "varimax")
print(efa.3.ort)
#can we make this easier to read?
print(efa.3.ort, cut = .3)
#your adviser demands 3 decimal places
print(efa.3.ort, cut = .3, digits = 3)
#even easier to read?
print(efa.3.ort, cut = .3, digits = 3, sort = T)
#try a different orthogonal rotation?
efa.3.ort.bT<-fa(bfi[,1:25], nfactors = 3, rotate = "bentlerT")
print(efa.3.ort.bT, cut = .3, sort = T)
#how similar are these solutions? Let's check with a congruence coefficient
factor.congruence(efa.3.ort,efa.3.ort.bT)
#what about an oblique rotation instead?
efa.3.obl<-fa(bfi[,1:25], nfactors = 3, rotate = "oblimin")
print(efa.3.obl, cut = .3, sort = T)
factor.congruence(efa.3.ort,efa.3.obl)
x1<-rnorm(1000)
x2<-rnorm(1000)
y<- x1 + x2 + rnorm(1000)
x3<-x1 + x2
x4<-x1 - x2 #rotate 45 degrees
lm.1<-lm(y~x1+x2)
summary(lm.1)
